# ğŸ† Live Sports Event Tracker Service

A high-concurrency backend microservice designed to track live sports events. It utilizes a fully containerized architecture to schedule periodic polling jobs, fetch real-time scores, and publish updates to Kafka.

![Java 17](https://img.shields.io/badge/Java-17-orange?style=flat-square)
![Spring Boot 3](https://img.shields.io/badge/Spring_Boot-3.2-green?style=flat-square)
![Kafka](https://img.shields.io/badge/Kafka-KRaft-black?style=flat-square)
![Docker](https://img.shields.io/badge/Docker-Compose-blue?style=flat-square)

---

## ğŸ“– Overview

**Functionally**, this microservice acts as a real-time bridge between sports data providers and downstream consumers. It manages the lifecycle of live sports events through a REST API:
* **Trigger:** Clients mark specific matches as `LIVE` or `NOT_LIVE`.
* **Action:** For every live event, the service triggers a dedicated background job that polls an external API for score updates every 10 seconds.
* **Output:** It transforms the raw data and publishes standardized score update messages to a **Kafka** topic.

**Technically**, the system is architected to handle high concurrency with operational precision:
* **O(1) Latency Control:** Instead of a simple batch loop, it uses a **Dynamic Scheduling Strategy** (`ConcurrentHashMap` + `ScheduledFuture`). This allows specific events to be started or stopped instantly without iterating through a global list.
* **Zero-Dependency Runtime:** The entire stack (Java App + Kafka) runs in Docker, requiring no local Java installation.
* **Resilience & Efficiency:** Configured with strict memory limits (`-Xmx256m`) and HTTP timeouts to ensure stability on constrained cloud infrastructure.

---

## ğŸ— Architecture & Design



### 1. Concurrency Strategy: Dynamic vs. Global
The system supports two scheduling modes via `app.scheduling.mode`. We default to **Dynamic Mode**.
* **Mechanism:** Uses a `ConcurrentHashMap` to manage a unique `ScheduledFuture` for each event.
* **Benefit:** Allows precise start/stop control for specific events without iterating through a global list.
* **Safety:** Implemented **Atomic Locking** (`computeIfAbsent`) to prevent race conditions.

### 2. Resilience & Resource Management
* **Memory Safety:** The Docker container is capped at **256MB RAM** via `JAVA_TOOL_OPTIONS` to prevent Out-Of-Memory (OOM) kills on small VMs.
* **Timeouts:** The `RestTemplate` uses strict **5-second timeouts** to prevent thread starvation if the external provider hangs.

### 3. Observability
* **Distributed Tracing:** Implemented `MdcInterceptor` and manual context propagation.
* **Outcome:** Logs are tagged with `[EventId: match-123]`, even inside background threads.

---

## ğŸ›  Prerequisites

* **Docker & Docker Compose** (The only strict requirement)
* **Make** (Recommended for automation)
* **curl** & **jq** (Optional, for manual testing)
* **Postman** (Optional: Import `Sporty_Event_Tracker.postman_collection.json` for GUI testing)

---

## ğŸš€ Getting Started

We provide a `Makefile` to automate the entire lifecycle.

### Option A: Using Make (Recommended)

1.  **Start the System:**
    ```bash
    make start
    ```
    *This builds the Docker image, starts Kafka (with memory limits), and waits for the application to be healthy.*

2.  **Watch the Logs:**
    ```bash
    make logs
    ```

3.  **Run an End-to-End Test:**
    ```bash
    make quick-test
    ```
    *This runs a script that starts an event, waits 15s for polling logs, and then stops the event.*

4. **Stop & Cleanup**
    
    To stop the application but keep data (Kafka topics):

    ```bash
    make stop
    ```

    To stop the application, **delete data volumes**, and remove build artifacts (Factory Reset):

    ```bash
    make clean
    ```

### Option B: Without Make (Windows / Manual)

1.  **Make script executable:**
    ```bash
    chmod +x docker.sh
    ```

2.  **Start the System:**
    ```bash
    ./docker.sh
    ```

3.  **Manual Testing:**
    Use the `curl` commands in the **API Usage** section below.

4.  **Stop & Cleanup:**
    
    To stop the services:
    ```bash
    docker-compose down
    ```
    
    To **factory reset** (delete Kafka data volumes):
    ```bash
    docker-compose down -v
    ```

---

## ğŸ”Œ API Usage

### 1. Start Tracking an Event

```bash
curl -X POST http://localhost:8080/events/status \
  -H "Content-Type: application/json" \
  -d '{
    "eventId": "match-001",
    "status": "LIVE"
  }'
```

### 2. Stop Tracking

```bash
curl -X POST http://localhost:8080/events/status \
  -H "Content-Type: application/json" \
  -d '{
    "eventId": "match-001",
    "status": "NOT_LIVE"
  }'
```

### 3. Mock Scores API (Debug)

Check the random score generator directly:

```bash
curl -X GET http://localhost:8080/mock-api/score/match-001
```

-----

## âš™ï¸ Configuration

Configuration is managed via `src/main/resources/application.yml` and `docker-compose.yml`.

| Property | Value | Description |
|----------|---------|-------------|
| `app.scheduling.mode` | `dynamic` | Strategy selection (per-event vs batch) |
| `app.scheduling.fixed-rate` | `10000` | Polling interval (10s) |
| `JAVA_TOOL_OPTIONS` | `-Xmx256m` | Hard memory limit for the Java Container |
| `KAFKA_HEAP_OPTS` | `-Xmx512M` | Hard memory limit for the Kafka Broker |

-----

## ğŸ“‚ Project Structure

```text
sporty-event-tracker/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”œâ”€â”€ java/com/sporty/eventtracker/
â”‚   â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ MdcInterceptor.java      # Distributed tracing context
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ RestConfig.java          # RestTemplate with timeouts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ SchedulerConfig.java     # ThreadPool settings
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ WebMvcConfig.java        # Interceptor registration
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ controllers/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ EventController.java     # Main API endpoint
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ HomeController.java      # Basic health check
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ MockScoreApiController.java
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ dto/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ EventResponse.java       # Standardized API response
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ EventStatus.java         # Enum (LIVE/NOT_LIVE)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ EventStatusUpdate.java   # Request Payload
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ interfaces/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ EventScheduler.java      # Strategy Interface
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ schedulers/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DynamicEventScheduler.java # ConcurrentHashMap Strategy
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ GlobalEventScheduler.java  # Batch Strategy
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ScorePollingService.java       # Core Business Logic
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ScoreUpdateProducer.java       # Kafka Producer
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ SportyEventTrackerApplication.java
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚       â””â”€â”€ application.yml              # App configuration
â”‚   â”‚
â”‚   â””â”€â”€ test/                                # Unit & Integration Tests
â”‚       â””â”€â”€ java/com/sporty/eventtracker/
â”‚           â”œâ”€â”€ controllers/EventControllerTest.java
â”‚           â”œâ”€â”€ services/ScorePollingServiceTest.java
â”‚           â””â”€â”€ services/schedulers/
â”‚               â”œâ”€â”€ DynamicEventSchedulerTest.java
â”‚               â””â”€â”€ GlobalEventSchedulerTest.java
â”‚
â”œâ”€â”€ docker-compose.yml                       # Kafka Infrastructure (KRaft)
â”œâ”€â”€ Dockerfile                               # Multi-stage Gradle build
â”œâ”€â”€ Makefile                                 # Automation commands
â”œâ”€â”€ docker.sh                                # Smart startup script
â”œâ”€â”€ build.gradle                             # Gradle build configuration
â””â”€â”€ settings.gradle                          # Gradle settings
```

-----

## ğŸ¤– AI Usage Disclosure

In compliance with the assignment requirements, AI tools (ChatGPT/Cursor) were leveraged for:

1.  **Boilerplate Generation:** Generating initial Unit Test skeletons and Docker configurations.
2.  **Debugging:** Troubleshooting specific Spring Boot 3 reflection issues with `@PathVariable`.
3.  **Documentation:** Assisting in drafting the `Makefile` and `README.md` structure.

-----

## â“ Troubleshooting

**"Service failed to start within 60 seconds"**

  * Your VM might be slow. Edit `docker.sh` and increase `max_attempts` to 120.

**"Exit Code 137" (OOM)**

  * The memory limits (`-Xmx`) in `docker-compose.yml` might be too tight for your specific VM. Try increasing them slightly (e.g., to 384m) if you have available RAM.

**"Connection Refused"**

  * Kafka takes \~10 seconds to elect a controller. The startup script handles this wait, but if running manually, give it time.
